{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.763728430491088\n",
      "[ 1.28683122e-04  6.87305926e-04  1.96977287e-05  1.06910455e-01\n",
      "  6.70484202e-05  8.89449206e-03  4.68304275e-03  7.26125219e-03\n",
      "  9.57541645e-04  5.89843765e-04  9.18477513e-05  1.69754876e-04\n",
      "  1.12025435e-03  1.59886052e-03  7.99938106e-03  1.23569070e-04\n",
      "  8.48263493e-05  2.81502864e-03  1.44517938e-03  2.79573771e-02\n",
      "  5.00001131e-05  1.21391439e-02  1.48331266e-03  1.98616707e-02\n",
      "  7.82199728e-05  3.88906271e-05  1.09189667e-02  3.29399329e-03\n",
      "  2.34578239e-02  9.39871519e-05  1.76311410e-03  3.08748829e-04\n",
      "  3.59665466e-04  5.60392341e-03  4.04458267e-04  2.87215836e-05\n",
      "  5.14324306e-03  7.52385372e-04  1.50987171e-04  5.98638842e-05\n",
      "  7.46385949e-03  1.69990376e-04  4.79140627e-03  1.98474069e-02\n",
      "  1.76738554e-03  2.01260575e-02  2.09155470e-02  6.72387947e-04\n",
      "  1.30957015e-02  4.38618181e-02  4.70914038e-04  1.68345510e-03\n",
      "  5.19008353e-03  3.48707063e-03  1.96088496e-06  4.68117711e-02\n",
      "  2.07288461e-04  1.12411821e-04  2.96875238e-04  7.70784013e-05\n",
      "  3.85749755e-02  2.86971194e-03  1.40167281e-03  2.94395293e-02\n",
      "  4.34104549e-04  1.45088024e-03  3.34847682e-04  5.55687543e-03\n",
      "  5.81699760e-04  6.33137977e-02  8.80609574e-05  3.93251966e-02\n",
      "  3.07670807e-02  2.55788428e-03  6.47858653e-04  4.51922791e-03\n",
      "  5.83796030e-03  1.38866042e-02  1.02520098e-03  3.03280846e-05\n",
      "  2.72967970e-04  5.01575832e-03  1.73467773e-03  1.98584804e-03\n",
      "  7.94665284e-03  8.95713703e-04  8.65351401e-02  2.03131833e-02\n",
      "  1.71967540e-03  1.51489182e-02  5.24802543e-04  1.93496067e-06\n",
      "  1.16880801e-03  5.02233546e-04  1.56939338e-01  4.52218913e-03\n",
      "  2.23069886e-05  7.08059706e-04  3.26393008e-04 -9.99575130e-01]\n",
      "[1.28683122e-04 6.87305926e-04 1.96977287e-05 1.06910455e-01\n",
      " 6.70484202e-05 8.89449206e-03 4.68304275e-03 7.26125219e-03\n",
      " 9.57541645e-04 5.89843765e-04 9.18477513e-05 1.69754876e-04\n",
      " 1.12025435e-03 1.59886052e-03 7.99938106e-03 1.23569070e-04\n",
      " 8.48263493e-05 2.81502864e-03 1.44517938e-03 2.79573771e-02\n",
      " 5.00001131e-05 1.21391439e-02 1.48331266e-03 1.98616707e-02\n",
      " 7.82199728e-05 3.88906271e-05 1.09189667e-02 3.29399329e-03\n",
      " 2.34578239e-02 9.39871519e-05 1.76311410e-03 3.08748829e-04\n",
      " 3.59665466e-04 5.60392341e-03 4.04458267e-04 2.87215836e-05\n",
      " 5.14324306e-03 7.52385372e-04 1.50987171e-04 5.98638842e-05\n",
      " 7.46385949e-03 1.69990376e-04 4.79140627e-03 1.98474069e-02\n",
      " 1.76738554e-03 2.01260575e-02 2.09155470e-02 6.72387947e-04\n",
      " 1.30957015e-02 4.38618181e-02 4.70914038e-04 1.68345510e-03\n",
      " 5.19008353e-03 3.48707063e-03 1.96088496e-06 4.68117711e-02\n",
      " 2.07288461e-04 1.12411821e-04 2.96875238e-04 7.70784013e-05\n",
      " 3.85749755e-02 2.86971194e-03 1.40167281e-03 2.94395293e-02\n",
      " 4.34104549e-04 1.45088024e-03 3.34847682e-04 5.55687543e-03\n",
      " 5.81699760e-04 6.33137977e-02 8.80609574e-05 3.93251966e-02\n",
      " 3.07670807e-02 2.55788428e-03 6.47858653e-04 4.51922791e-03\n",
      " 5.83796030e-03 1.38866042e-02 1.02520098e-03 3.03280846e-05\n",
      " 2.72967970e-04 5.01575832e-03 1.73467773e-03 1.98584804e-03\n",
      " 7.94665284e-03 8.95713703e-04 8.65351401e-02 2.03131833e-02\n",
      " 1.71967540e-03 1.51489182e-02 5.24802543e-04 1.93496067e-06\n",
      " 1.16880801e-03 5.02233546e-04 1.56939338e-01 4.52218913e-03\n",
      " 2.23069886e-05 7.08059706e-04 3.26393008e-04 4.24869527e-04]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3a5cdbf59bea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m \u001b[0mback_prop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_stack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;31m#for l, y in layer_stack: print(l,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;31m#activate_layer(W1, b1, relu)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-3a5cdbf59bea>\u001b[0m in \u001b[0;36mback_prop\u001b[1;34m(layer_stack, dloss)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m#previous_activation output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,) (3,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def relu(x, d=0):\n",
    "    #d==True during backprop\n",
    "    x[x < 0] = 0\n",
    "    if d: x = np.where(x <= 0, 1, 0)\n",
    "    return x\n",
    "\n",
    "def softmax(x, d=0):\n",
    "    #d==True during backprop\n",
    "    x = np.exp(x) / sum(np.exp(x))\n",
    "    if d: x = np.where(x < 0, 0, 1)\n",
    "    return x\n",
    "\n",
    "def KL_divergence(X, Y, d=0):\n",
    "    #d==True during backprop\n",
    "    #Derived formula obtained from http://proceedings.mlr.press/v37/theis15-supp.pdf\n",
    "    loss = - Y.dot(np.log(X)) if not d else np.dot((X-Y).T, np.identity(X.shape[0]))\n",
    "    return loss\n",
    "\n",
    "# Shape(3, 3)\n",
    "# 3 input neurons and one layer with 10 hidden neurons and an output of three neurons\n",
    "\n",
    "def rnn(shape, activation):\n",
    "    # [3, 10, 3 ,1]\n",
    "    # return layer_stack\n",
    "    pass\n",
    "\n",
    "def initialize_layer(this_layer_neurons, previous_layer_neurons, \n",
    "                     activation_function=relu): \n",
    "    size = (this_layer_neurons, previous_layer_neurons)\n",
    "    weights = np.random.standard_normal(size)\n",
    "    # http://cs231n.github.io/neural-networks-2/ initialized at 0.001\n",
    "    biases = np.full(previous_layer_neurons, 0.001)\n",
    "    previous_activation = np.zeros(previous_layer_neurons)\n",
    "    previous_pre_activation = np.zeros(previous_layer_neurons)\n",
    "    layer = dict([(\"W\", weights), (\"b\", biases), (\"f\", activation_function), \n",
    "                  (\"a\", previous_activation)])\n",
    "    return layer\n",
    "\n",
    "def activate_layer(layer, d=0):\n",
    "    #this_layer_weights\n",
    "    W = layer[\"W\"]\n",
    "    #previous_layer_output\n",
    "    a = layer[\"a\"]\n",
    "    #bias\n",
    "    b = layer[\"b\"]\n",
    "    #activation_function\n",
    "    f = layer[\"f\"]\n",
    "    #logits aka. pre-nonlinearity activation\n",
    "    z = a.dot(W) + b\n",
    "    return f(z, d=d)\n",
    "\n",
    "def add_layer(layer, L=[]):\n",
    "    #a layer must be a dict of weigts, bias, activation function, \n",
    "    #and a tensor of the previous layers activation output\n",
    "    return L + [layer]\n",
    "\n",
    "def feed_input_to_stack(input_data, layer_stack):\n",
    "    #set previous_layer_activation of first layer to be the input\n",
    "    layer_stack[0][\"a\"] = input_data\n",
    "    return layer_stack\n",
    "\n",
    "def forward_pass(layer_stack):\n",
    "    #previous_activation output\n",
    "    out = None\n",
    "    for i, layer in enumerate(layer_stack):\n",
    "        if out is not None: layer_stack[i][\"a\"] = out\n",
    "        out = activate_layer(layer)\n",
    "    return out, layer_stack\n",
    "\n",
    "def back_prop(layer_stack, dloss):\n",
    "    for layer in reversed(layer_stack[:-1]):\n",
    "        #I recompute z to save some memory and lines of code\n",
    "        out = activate_layer(layer, d=True)\n",
    "        #previous_activation output\n",
    "        a = layer[\"a\"]\n",
    "        x = np.multiply(dloss, out)\n",
    "        print(x)\n",
    "        dz = x.dot(a)\n",
    "        break\n",
    "\n",
    "input_data = np.array([0 for _ in range(99)] + [1])    \n",
    "    \n",
    "#layer_stack = add_layer(initialize_layer(100, 3, relu))\n",
    "#layer_stack = add_layer(initialize_layer(3, 10, relu), layer_stack)\n",
    "#layer_stack = add_layer(initialize_layer(10, 3, relu), layer_stack)\n",
    "#layer_stack = add_layer(initialize_layer(3, 100, softmax), layer_stack)\n",
    "#layer_stack = feed_input_to_stack(input_data, layer_stack)\n",
    "\n",
    "layer_stack = add_layer(initialize_layer(10, 3, relu))\n",
    "\n",
    "out, layer_stack = forward_pass(layer_stack)\n",
    "loss = KL_divergence(out, input_data)\n",
    "dloss = KL_divergence(out, input_data, d=True)\n",
    "print(loss)\n",
    "print(dloss)\n",
    "print(out)\n",
    "\n",
    "back_prop(layer_stack, dloss)\n",
    "#for l, y in layer_stack: print(l,)\n",
    "#activate_layer(W1, b1, relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W': array([[-1.01021815e+00, -5.76838027e-01, -1.79904516e+00,\n",
       "          2.32386539e+00, -1.43571296e+00,  1.09281349e+00,\n",
       "          7.79127919e-01,  1.09636225e+00,  4.28375761e-01,\n",
       "         -7.98242137e-01, -1.20590313e+00, -1.38917876e+00,\n",
       "          8.28312075e-02, -5.65594187e-03,  9.99967186e-01,\n",
       "         -1.24186656e+00, -1.01583585e+00,  3.86691121e-01,\n",
       "          8.50199074e-02,  1.80029894e+00, -1.33764108e+00,\n",
       "          1.18521292e+00,  3.82608203e-01,  1.14476559e+00,\n",
       "         -1.17031402e+00, -1.73409200e+00,  1.05582941e+00,\n",
       "         -9.59102425e-02,  1.24104277e+00, -1.35648320e+00,\n",
       "          1.81294122e-01, -3.86528001e-01, -3.88608829e-01,\n",
       "          4.35757865e-01, -9.57757592e-01, -1.91095031e+00,\n",
       "          4.83586560e-01, -4.07495477e-01, -9.05027166e-01,\n",
       "         -1.20617998e+00,  6.21360664e-01, -9.49408126e-01,\n",
       "          5.29798010e-01,  1.85742697e+00,  7.13410254e-03,\n",
       "          1.59637506e+00,  1.63837454e+00, -2.74462330e-01,\n",
       "          1.10495318e+00,  1.54114734e+00, -5.56417887e-01,\n",
       "          6.79890957e-01,  7.60983496e-01,  6.69223489e-01,\n",
       "         -3.11922580e+00,  1.88383297e+00, -1.03936340e+00,\n",
       "         -1.03197256e+00, -8.53857944e-01, -1.27228841e+00,\n",
       "          1.23935014e+00,  9.81012514e-02,  1.26243386e-02,\n",
       "          1.81492806e+00, -5.48662096e-01,  1.31290378e-01,\n",
       "         -6.37342177e-01,  1.08775744e+00, -3.05307873e-01,\n",
       "          1.62256847e+00, -1.14856261e+00,  1.36469137e+00,\n",
       "          1.71977959e+00,  2.67021961e-01, -5.23939620e-01,\n",
       "          3.66885749e-01,  6.62260160e-01,  1.33510018e+00,\n",
       "         -3.01093901e-01, -1.68369391e+00, -7.10889678e-01,\n",
       "          4.38581208e-01,  2.75757930e-01,  4.43298248e-01,\n",
       "          8.34956044e-01,  3.36477628e-02,  1.75253097e+00,\n",
       "          1.63565554e+00, -3.99716646e-03,  1.08819828e+00,\n",
       "         -5.37482097e-01, -2.81360683e+00, -1.20442211e-01,\n",
       "         -3.50567012e-01,  1.89861128e+00,  4.24862735e-01,\n",
       "         -1.64313235e+00, -2.67726573e-01, -9.76921261e-01,\n",
       "         -4.66645464e-01],\n",
       "        [-3.25872677e-01,  1.14500228e+00, -7.79243881e-01,\n",
       "         -7.04905009e-01,  1.13093494e-01, -5.73361007e-01,\n",
       "         -5.54788097e-01, -9.72063525e-01, -2.18393365e+00,\n",
       "          1.72672574e+00, -1.94905099e-01,  1.69146960e+00,\n",
       "         -5.25834114e-01,  4.97155989e-01, -4.08946569e-01,\n",
       "          5.09275392e-01, -1.09405007e+00,  2.51273000e-02,\n",
       "         -5.14947861e-02, -1.18709769e+00, -8.29404898e-01,\n",
       "         -3.47388568e-01, -1.17377515e+00,  7.45539039e-01,\n",
       "         -6.39593981e-01,  2.55009866e-01, -3.88648783e-02,\n",
       "          2.22320252e+00,  6.82050020e-01,  4.41626022e-01,\n",
       "         -5.34625427e-02, -1.12184206e+00, -8.24179486e-01,\n",
       "          1.13756389e+00,  1.63926442e+00,  3.76548917e-01,\n",
       "          7.86577558e-01,  6.49824699e-01, -4.36916986e-01,\n",
       "         -1.00556243e+00,  9.50308653e-01, -3.73736379e-02,\n",
       "          4.70258323e-01, -2.06172550e+00,  6.36831824e-01,\n",
       "         -1.00746873e+00, -1.09986338e+00, -8.71297468e-02,\n",
       "          1.12446867e-01,  6.87281976e-01,  3.47588356e-01,\n",
       "         -2.10422057e+00, -2.88402046e-01, -6.81276147e-01,\n",
       "          4.35220463e-02, -5.38511540e-01,  6.92976766e-01,\n",
       "         -4.96576075e-01,  6.43769837e-01, -2.65978625e-01,\n",
       "          1.63195557e+00,  1.19785230e+00,  1.75576542e-01,\n",
       "         -1.14673581e+00,  1.62708310e-01, -2.26205781e-01,\n",
       "          1.95515858e-02, -1.44548766e+00, -2.40428562e-01,\n",
       "          1.06277992e+00, -5.00509071e-01,  1.17498681e+00,\n",
       "         -6.88473622e-01,  3.14636083e-01,  8.24642633e-01,\n",
       "          1.00077564e+00,  3.23363325e-01, -6.82488913e-01,\n",
       "          8.17618805e-01, -4.14999631e-01, -7.83395773e-02,\n",
       "          9.16176628e-01, -4.56221515e-01, -8.59431948e-01,\n",
       "          2.28196822e-01, -7.56381989e-01,  1.14359720e+00,\n",
       "         -1.14457434e+00,  6.28763041e-01,  4.54607805e-01,\n",
       "          4.78496397e-01, -1.18500426e+00,  3.54956746e-01,\n",
       "         -3.40786090e-01,  1.69735809e+00,  7.73749864e-01,\n",
       "         -1.15720736e+00, -1.56222402e-02,  1.30805171e+00,\n",
       "         -2.00986550e-01],\n",
       "        [-1.94756723e-01, -6.32594399e-02,  4.88364132e-01,\n",
       "          1.09016982e-02, -1.05851913e+00,  9.11259226e-02,\n",
       "          1.67726143e+00,  4.60315677e-01,  9.83614928e-01,\n",
       "          1.41682253e+00,  1.94421421e+00,  4.20662792e-01,\n",
       "          6.60638778e-01,  3.01114434e-01, -1.51457944e+00,\n",
       "          8.08275626e-01, -6.82461755e-01, -1.45697428e+00,\n",
       "          1.39414531e-01,  4.15169273e-01, -2.01183685e-01,\n",
       "          7.45222439e-01,  3.35259832e-01,  8.21384211e-02,\n",
       "          1.34976418e-01, -1.46768401e+00, -1.68407952e+00,\n",
       "          2.57423966e-03,  1.94969148e+00, -8.36950666e-01,\n",
       "         -1.02133587e+00,  1.71364390e+00,  3.92702122e-01,\n",
       "         -1.73236139e-01, -6.40235590e-01,  9.82545624e-01,\n",
       "         -9.24778731e-01, -9.79094335e-01, -1.45149527e+00,\n",
       "         -8.97795151e-01,  7.93854594e-01, -1.90736939e-01,\n",
       "          2.53133369e-01,  2.05740654e+00,  9.54551805e-01,\n",
       "         -1.39173429e+00, -4.12325876e-02,  1.85337580e-01,\n",
       "         -8.34114910e-01,  1.30656322e+00, -4.39717837e-02,\n",
       "          6.19589101e-01,  3.24355696e+00, -1.23142281e+00,\n",
       "         -1.54717950e+00, -1.26492037e+00, -1.58224250e-01,\n",
       "          3.76748580e-01, -8.92694756e-01,  1.42543462e+00,\n",
       "          2.37105660e-02,  1.96231891e+00,  6.22538150e-01,\n",
       "          1.01617982e+00,  1.95394254e-02,  4.75658493e-01,\n",
       "         -7.75516310e-01, -3.11742529e+00, -1.79553438e+00,\n",
       "          1.60616575e-01,  9.37938959e-01,  7.23945038e-01,\n",
       "         -2.01048103e-01,  1.88430490e-01,  4.75861381e-01,\n",
       "         -1.38675984e+00, -2.91528115e+00, -1.98735790e+00,\n",
       "          2.94687227e-01,  1.33494618e+00,  1.72937215e+00,\n",
       "          5.79460912e-01, -3.44001184e-01,  1.69433275e+00,\n",
       "          2.64363698e-01,  1.23497097e+00,  6.16977808e-01,\n",
       "         -3.26328357e-01, -1.28471537e-01,  1.52245686e+00,\n",
       "         -3.61880452e-01, -8.07400815e-01, -1.85447668e-01,\n",
       "         -7.83827559e-01,  8.09404897e-01, -4.45288064e-01,\n",
       "         -5.61922571e-01,  5.24224694e-01, -2.65885771e+00,\n",
       "          2.70332629e-01]]),\n",
       " 'a': array([2.07621347, 0.52733027, 0.        ]),\n",
       " 'b': array([0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "        0.001]),\n",
       " 'f': <function __main__.softmax>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_stack[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.734723475976807e-17"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(dloss,out).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vectorizer(tokenized_text):\n",
    "    words = set(tokenized_text)\n",
    "    vocab_size = len(words)\n",
    "    onehot = np.identity(vocab_size)\n",
    "    \n",
    "    word2onehot = dict(zip(words, onehot))\n",
    "    onehotargmax2word = dict(zip(onehot.argmax(axis=1), words)) \n",
    "                                #cant use array as key\n",
    "                                #onehot.argmax(axis=1) same as range(vocab_size)\n",
    "    \n",
    "    return word2onehot, onehotargmax2word\n",
    "    \n",
    "    \n",
    "tokenized_text = \"this is a test to se how well it all works -did i say it was a test?\".split()\n",
    "\n",
    "w2o, o2w = one_hot_vectorizer(tokenized_text)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
